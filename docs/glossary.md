*[accuracy]: Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition: $Accuracy=\frac{Number~of~correct~predictions}{Total~number~of~predictions}$. More at https://developers.google.com/machine-learning/crash-course/classification/accuracy
*[consolidation]: Process of matching the standardized citation attributes with high quality domain specific databases. Enrich the final output with additional attributes such as the DOI, the PMID and the open access url inter allia.
*[Crossref]: Crossref interlinks millions of items from a variety of content types, including journals, books, conference proceedings, working papers, technical reports, and data sets. Linked content includes materials from Scientific, Technical and Medical (STM) and Social Sciences and Humanities (SSH) disciplines.
*[PUBMED]: PubMed is a free search engine accessing primarily the MEDLINE database of references and abstracts on life sciences and biomedical topics.
*[DOCDB]: The EPO worldwide bibliographic data, so-called DOCDB includes bibliographic data from over 90 countries worldwide. The data goes back as far as the 1830s for some patent authorities. More at https://www.epo.org/searching-for-patents/data/bulk-data-sets/docdb.html#tab-1
*[DOI]: A digital object identifier (DOI) is a persistent identifier or handle used to identify objects uniquely, standardized by the International Organization for Standardization (ISO). DOIs are in wide use mainly to identify academic, professional, and government information, such as journal articles, research reports and data sets *inter allia*. Publisher quality bibliographical attributes can be retrieved from the DOI.
*[extraction]: Process of detecting and staging entity, NPL and patent citations from raw text documents.
*[NPL]: Any literature which is publicly available and not a patent or a pending/expired publication in a patent office can be an NPL.
*[parsing]: Process of structuring a free-form NPL or patent citations into standard bibliographic attributes (e.g. title, authors, journal, etc)
*[precision]: Precision attempts to answer the following question: "What proportion of positive identifications was actually correct?". Formerly, precision is defined as: $Precision = \frac{True~Positive}{True~Positive + False~Positive}$. More at https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall
*[recall]: Recall attempts to answer the following question: "What proportion of actual positives was identified correctly?". Formerly, precision is defined as: $Precision = \frac{True~Positive}{True~Positive + False~Negative}$. More at https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall
*[HTML]: Hyper Text Markup Language
*[W3C]: World Wide Web Consortium
